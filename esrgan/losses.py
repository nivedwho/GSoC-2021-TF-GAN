import os 
import tensorflow as tf

def pixel_loss(y_true, y_pred):
  """ To calculate the L1 Loss.
  Args :
      y_true : Original HR image present in the dataset.
      y_pred : Image generated by the generator network.
  Returns :
      Mean absolute difference between the two images.
  """
  y_true = tf.cast(y_true, tf.float32)
  y_pred = tf.cast(y_pred, tf.float32)
  return tf.reduce_mean(tf.reduce_mean(tf.abs(y_true - y_pred), axis=0))


def ragan_generator_loss(d_real, 
                         d_fake,
                         scope=None):
  """  To calculate the adversarial loss for generator
       network using a relativistic discriminator. 
  
  Args:
    d_real: Discriminator output on real data.
    d_fake: Discriminator output on generated data. Expected
            to be in the range of (-inf, inf).
    scope: The scope for the operations performed in computing the loss.
  Returns:
    Adversarial loss for generator.
  """
  with tf.compat.v1.name_scope(
      scope,
      'relativistic_avg_generator_loss',
      values=[d_real, d_fake]):
    def get_logits(x, y):
      return x - tf.reduce_mean(y)
      
    real_logits = get_logits(d_real, d_fake)
    fake_logits = get_logits(d_fake, d_real)

    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
        labels=tf.zeros_like(real_logits), logits=real_logits))  
    fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
        labels=tf.ones_like(fake_logits), logits=fake_logits))

  return real_loss + fake_loss
 

def ragan_discriminator_loss(d_real, 
                             d_fake,
                             scope=None):
  """  To calculate the adversarial loss for discriminator
       network using a relativistic discriminator. 
  
  Args:
    d_real: Discriminator output on real data.
    d_fake: Discriminator output on generated data. Expected
            to be in the range of (-inf, inf).
    scope: The scope for the operations performed in computing the loss.
  Returns:
    Adversarial loss for discriminator.
  """
  with tf.compat.v1.name_scope(
      scope,
      'relativistic_avg_discriminator_loss',
      values=[d_real, d_fake]):
    def get_logits(x, y):
      return x - tf.reduce_mean(y)
    
    real_logits = get_logits(d_real, d_fake)
    fake_logits = get_logits(d_fake, d_real)

    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
            labels=tf.ones_like(real_logits), logits=real_logits))
    fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
        labels=tf.zeros_like(fake_logits), logits=fake_logits))

  return real_loss + fake_loss

def vgg_loss(weight=None, input_shape=None):
  """ Perceptual Loss calculation using pre-trained VGG19
      model before activation as mentioned in the paper.
  Args:
      weights: Weights to be loaded.
      input_shape: Shape of input image.

  Returns :
      Perceptual loss
  """
  vgg_model = tf.keras.applications.vgg19.VGG19(
      input_shape=input_shape, weights=weight, include_top=False
  )

  for layer in vgg_model.layers:
    layer.trainable = False

  vgg_model.get_layer("block5_conv4").activation = lambda x: x
  vgg = tf.keras.Model(
      inputs=[vgg_model.input],
      outputs=[vgg_model.get_layer("block5_conv4").output])

  def loss(y_true, y_pred):
    return tf.compat.v1.losses.absolute_difference(vgg(y_true), vgg(y_pred))

  return loss
